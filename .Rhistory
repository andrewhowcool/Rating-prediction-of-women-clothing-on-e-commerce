objective = "multi:softprob",
"num_class" = 6
#objective = "reg:linear"
)
# xgboost model
xgbModel_valid <- xgb.train(data = trainData,
params = my_params,
maximize = FALSE,
#nrounds = 92
nrounds = bestIteration
)
#importance
importance_matrix <- xgb.importance(colnames(trainData_first$data),model = xgbModel_valid)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix[1:8,])
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
#Training data
train_df <- df2 %>%
select( recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
group_by() %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(recommended)) %>%
na.omit
str(train_df)
#Transform into dgcMatrix
x_train <- train_df %>% select(-rating) %>% as.matrix()
y_train <- train_df$rating %>% as.matrix()
trainData_first <- list(data = as(x_train, "dgCMatrix"),label = y_train)
trainData <- xgb.DMatrix(trainData_first$data,label = trainData_first$label)
#Testing data
test_df <- testing %>%
group_by() %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(recommended)) %>%
na.omit
#Transform into dgcMatrix
x_test <- test_df %>% select(-rating) %>% as.matrix()
y_test <- test_df$rating %>% as.matrix()
testData <- list(data = as(x_test, "dgCMatrix"),label = y_test)
#---------------------------------- Params adjusting----------------------------------------------------------------------
paramTable <- expand.grid(eta = c(0.03), #0.06
max_depth = c(2),  #2
subsample = c(0.6),
colsample_bytree = c(0.6))
#Cross vaildation
cvOutput <- NULL
for(iy in c(1:nrow(paramTable))){
#params setting
params <- list(booster = "gbtree",
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy],
#"eval_metric" = "mae",
"eval_metric" = "mlogloss",
"num_class" = 6,
#objective = "reg:linear",
objective = "multi:softmax"
)
#Cross validation
cvResult <- xgb.cv(params = params,
data = trainData,
nrounds = 300,
nfold = 5,
early_stopping_rounds = 10,
verbose = 1)
#output
cvOutput <- cvOutput %>%
bind_rows(tibble(paramsNum = iy,
bestIteration = cvResult$best_iteration,
bestCvrmse = cvResult$evaluation_log$train_mlogloss_mean[bestIteration],
bestCvrmse_test = cvResult$evaluation_log$test_mlogloss_mean[bestIteration],
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy]))
print(tail(cvOutput,10))
}
# ---------------------------------------------------Best params-------------------------------------------------------------------
bestCvSite <- which(cvOutput$bestCvrmse_test == min(cvOutput$bestCvrmse_test))
bestCvrmse <- cvOutput$bestCvrmse[bestCvSite]
bestIteration <- cvOutput$bestIteration[bestCvSite]
bestParamsNum <- cvOutput$paramsNum[bestCvSite]
#bestCvSite <- which(cvOutput$bestCvmae_test == min(cvOutput$bestCvmae_test))
#bestCvmae <- cvOutput$bestCvmae[bestCvSite]
#bestIteration <- cvOutput$bestIteration[bestCvSite]
#bestParamsNum <- cvOutput$paramsNum[bestCvSite]
# ------------------------------------------------Besst model training-------------------------------------------------------------------
# params
my_params <- list(booster = "gbtree",
eta = paramTable$eta[bestParamsNum],
#eta = 0.1,
max_depth = paramTable$max_depth[bestParamsNum],
#max_depth = 10,
subsample = paramTable$subsample[bestParamsNum],
#subsample = 0.6,
colsample_bytree = paramTable$colsample_bytree[bestParamsNum],
#colsample_bytree = 0.6,
#"eval_metric" = "mae",
"eval_metric" = "mlogloss",
objective = "multi:softmax",
"num_class" = 6
#objective = "reg:linear"
)
# xgboost model
xgbModel_valid <- xgb.train(data = trainData,
params = my_params,
maximize = FALSE,
#nrounds = 92
nrounds = bestIteration
)
#importance
importance_matrix <- xgb.importance(colnames(trainData_first$data),model = xgbModel_valid)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix[1:8,])
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
testData$data
str(test_df)
str(train_df)
#Testing data
test_df <- testing %>%
group_by() %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
select(-c(v1,clothing_id)) %>%
na.omit
#Transform into dgcMatrix
x_test <- test_df %>% select(-rating) %>% as.matrix()
y_test <- test_df$rating %>% as.matrix()
testData <- list(data = as(x_test, "dgCMatrix"),label = y_test)
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
str(test_df)
str(train_df)
#Testing data
test_df <- testing %>%
select( recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
group_by() %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(v1,clothing_id)) %>%
na.omit
str(test_df)
#Testing data
test_df <- testing %>%
group_by() %>%
select( recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(v1,clothing_id)) %>%
na.omit
str(test_df)
str(train_df)
#Transform into dgcMatrix
x_train <- train_df %>% select(-rating) %>% as.matrix()
y_train <- train_df$rating %>% as.matrix()
trainData_first <- list(data = as(x_train, "dgCMatrix"),label = y_train)
trainData <- xgb.DMatrix(trainData_first$data,label = trainData_first$label)
#Testing data
test_df <- testing %>%
group_by() %>%
select( recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(v1,clothing_id)) %>%
na.omit
#Transform into dgcMatrix
x_test <- test_df %>% select(-rating) %>% as.matrix()
y_test <- test_df$rating %>% as.matrix()
testData <- list(data = as(x_test, "dgCMatrix"),label = y_test)
#---------------------------------- Params adjusting----------------------------------------------------------------------
paramTable <- expand.grid(eta = c(0.03), #0.06
max_depth = c(2),  #2
subsample = c(0.6),
colsample_bytree = c(0.6))
#Cross vaildation
cvOutput <- NULL
for(iy in c(1:nrow(paramTable))){
#params setting
params <- list(booster = "gbtree",
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy],
#"eval_metric" = "mae",
"eval_metric" = "mlogloss",
"num_class" = 6,
#objective = "reg:linear",
objective = "multi:softmax"
)
#Cross validation
cvResult <- xgb.cv(params = params,
data = trainData,
nrounds = 300,
nfold = 5,
early_stopping_rounds = 10,
verbose = 1)
#output
cvOutput <- cvOutput %>%
bind_rows(tibble(paramsNum = iy,
bestIteration = cvResult$best_iteration,
bestCvrmse = cvResult$evaluation_log$train_mlogloss_mean[bestIteration],
bestCvrmse_test = cvResult$evaluation_log$test_mlogloss_mean[bestIteration],
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy]))
print(tail(cvOutput,10))
}
# ---------------------------------------------------Best params-------------------------------------------------------------------
bestCvSite <- which(cvOutput$bestCvrmse_test == min(cvOutput$bestCvrmse_test))
bestCvrmse <- cvOutput$bestCvrmse[bestCvSite]
bestIteration <- cvOutput$bestIteration[bestCvSite]
bestParamsNum <- cvOutput$paramsNum[bestCvSite]
#bestCvSite <- which(cvOutput$bestCvmae_test == min(cvOutput$bestCvmae_test))
#bestCvmae <- cvOutput$bestCvmae[bestCvSite]
#bestIteration <- cvOutput$bestIteration[bestCvSite]
#bestParamsNum <- cvOutput$paramsNum[bestCvSite]
# ------------------------------------------------Besst model training-------------------------------------------------------------------
# params
my_params <- list(booster = "gbtree",
eta = paramTable$eta[bestParamsNum],
#eta = 0.1,
max_depth = paramTable$max_depth[bestParamsNum],
#max_depth = 10,
subsample = paramTable$subsample[bestParamsNum],
#subsample = 0.6,
colsample_bytree = paramTable$colsample_bytree[bestParamsNum],
#colsample_bytree = 0.6,
#"eval_metric" = "mae",
"eval_metric" = "mlogloss",
objective = "multi:softmax",
"num_class" = 6
#objective = "reg:linear"
)
# xgboost model
xgbModel_valid <- xgb.train(data = trainData,
params = my_params,
maximize = FALSE,
#nrounds = 92
nrounds = bestIteration
)
#importance
importance_matrix <- xgb.importance(colnames(trainData_first$data),model = xgbModel_valid)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix[1:8,])
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
#importance
importance_matrix <- xgb.importance(colnames(trainData_first$data),model = xgbModel_valid)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix[1:8,])
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
adj_rating = round(test_rating)
#Cunfusion matrix
test_table <- tibble(test_ret = adj_rating) %>% mutate(act_ret = testData$label) %>%
mutate(true = as.numeric(test_ret == act_ret))
cm2 <- table(test_table$act_ret,test_table$test_ret, dnn = c("real", "predict"))
# Precision
pc1 <- cm2[1,1] / sum(cm2[, 1])
pc2 <- cm2[2,2] / sum(cm2[, 2])
pc3 <- cm2[3,3] / sum(cm2[, 3])
pc4 <- cm2[4,4] / sum(cm2[, 4])
pc5 <- cm2[5,5] / sum(cm2[, 5])
# Recall
rc1 <- cm2[1,1] / sum(cm2[1, ])
rc2 <- cm2[2,2] / sum(cm2[2, ])
rc3 <- cm2[3,3] / sum(cm2[3, ])
rc4 <- cm2[4,4] / sum(cm2[4, ])
rc5 <- cm2[5,5] / sum(cm2[5, ])
cm2
ACC <- mean(test_table$true) # 0.6154529 # 0.6439287
ACC
test_rating
step3 <- testing %>%
mutate(predict_rating = test_rating)
step3 <- test_df %>%
mutate(predict_rating = test_rating)
View(step3)
step3 <- testing %>%
na.omit() %>%
mutate(predict_rating = test_rating)
step3 <- testing %>%
na.omit()
#Testing data
test_df1 <- testing %>%
group_by() %>%
select(v1, recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating)))
test_df <- test_df1 %>%
select(-c(v1)) %>%
na.omit
#Transform into dgcMatrix
x_test <- test_df %>% select(-rating) %>% as.matrix()
y_test <- test_df$rating %>% as.matrix()
testData <- list(data = as(x_test, "dgCMatrix"),label = y_test)
#-----------------------------------------------------testing -----------------------------------------------------------------------
#Testing rating
test_rating = (predict(xgbModel_valid, testData$data)) %>% as.numeric()
adj_rating = round(test_rating)
#Cunfusion matrix
test_table <- tibble(test_ret = adj_rating) %>% mutate(act_ret = testData$label) %>%
mutate(true = as.numeric(test_ret == act_ret))
cm2 <- table(test_table$act_ret,test_table$test_ret, dnn = c("real", "predict"))
# Precision
pc1 <- cm2[1,1] / sum(cm2[, 1])
pc2 <- cm2[2,2] / sum(cm2[, 2])
pc3 <- cm2[3,3] / sum(cm2[, 3])
pc4 <- cm2[4,4] / sum(cm2[, 4])
pc5 <- cm2[5,5] / sum(cm2[, 5])
# Recall
rc1 <- cm2[1,1] / sum(cm2[1, ])
rc2 <- cm2[2,2] / sum(cm2[2, ])
rc3 <- cm2[3,3] / sum(cm2[3, ])
rc4 <- cm2[4,4] / sum(cm2[4, ])
rc5 <- cm2[5,5] / sum(cm2[5, ])
ACC <- mean(test_table$true) # 0.6154529 # 0.6439287
### compare f1 score ###
# rating 1
2*precision1*recall1/(precision1+recall1)
ACC
### compare f1 score ###
# rating 1
2*precision1*recall1/(precision1+recall1)
2*pc1*rc1/(pc1+rc1)
# rating 2
2*precision2*recall2/(precision2+recall2)
2*pc2*rc2/(pc2+rc2)
# rating 3
2*precision3*recall3/(precision3+recall3)
2*pc3*rc3/(pc3+rc3)
# rating 4
2*precision4*recall4/(precision4+recall4)
2*pc4*rc4/(pc4+rc4)
# rating 5
2*precision5*recall5/(precision5+recall5)
2*pc5*rc5/(pc5+rc5)
#  0.8639456   factor 0.7639752
ACC
step3 <- test_df1 %>%
mutate(predict_rating = test_rating)
View(step3)
#Training data
train_df <- df2 %>%
select( recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
group_by() %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating))) %>%
#select(-c(recommended)) %>%
na.omit
str(train_df)
#Transform into dgcMatrix
x_train <- train_df %>% select(-rating) %>% as.matrix()
y_train <- train_df$rating %>% as.matrix()
trainData_first <- list(data = as(x_train, "dgCMatrix"),label = y_train)
trainData <- xgb.DMatrix(trainData_first$data,label = trainData_first$label)
#Testing data
test_df1 <- testing %>%
group_by() %>%
select(v1, recommended, age, age_div, rating, positive_feedback, devision, class, department, review_vector, sum_sents, sum_senta, sum_sentb) %>%
mutate(age = as.numeric(age),
age_div = ordered(age_div),
recommended = as.factor(recommended),
positive_feedback = as.factor(positive_feedback),
devision = as.factor(devision),
class = as.factor(class),
department = as.factor(department),
review_vector = as.factor(review_vector),
#rating_recom = paste0(rating,"_",recommended),
#rating = if_else(as.numeric(rating) >= 4,3,if_else(as.numeric(rating) == 3,2,1))/3,
#rating = as.factor(as.numeric(rating)/5),
rating = as.factor(as.numeric(rating)))
test_df <- test_df1 %>%
select(-c(v1)) %>%
na.omit
#Transform into dgcMatrix
x_test <- test_df %>% select(-rating) %>% as.matrix()
y_test <- test_df$rating %>% as.matrix()
testData <- list(data = as(x_test, "dgCMatrix"),label = y_test)
#---------------------------------- Params adjusting----------------------------------------------------------------------
paramTable <- expand.grid(eta = c(0.03,0.06,0.1), #0.06
max_depth = c(2,5,10),  #2
subsample = c(0.6),
colsample_bytree = c(0.6))
#Cross vaildation
cvOutput <- NULL
for(iy in c(1:nrow(paramTable))){
#params setting
params <- list(booster = "gbtree",
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy],
#"eval_metric" = "mae",
"eval_metric" = "mlogloss",
"num_class" = 6,
#objective = "reg:linear",
objective = "multi:softmax"
)
#Cross validation
cvResult <- xgb.cv(params = params,
data = trainData,
nrounds = 300,
nfold = 5,
early_stopping_rounds = 10,
verbose = 1)
#output
cvOutput <- cvOutput %>%
bind_rows(tibble(paramsNum = iy,
bestIteration = cvResult$best_iteration,
bestCvrmse = cvResult$evaluation_log$train_mlogloss_mean[bestIteration],
bestCvrmse_test = cvResult$evaluation_log$test_mlogloss_mean[bestIteration],
eta = paramTable$eta[iy],
max_depth = paramTable$max_depth[iy],
subsample = paramTable$subsample[iy],
colsample_bytree = paramTable$colsample_bytree[iy]))
print(tail(cvOutput,10))
}
xx<-cvOutput %>% arrange(bestCvrmse_test)
View(xx)
View(df3)
